{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75b5b0c",
   "metadata": {},
   "source": [
    "#### Randomly Select 500 Samples for Human Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc93b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# 1) Read CSV\n",
    "# ======================\n",
    "base_dir = os.getcwd()   # works in Jupyter\n",
    "data_path = os.path.abspath(os.path.join(base_dir, '..', 'data'))\n",
    "classified_path = os.path.join(data_path, \"full_covid_abuse.csv\") \n",
    "df = pd.read_csv(classified_path)\n",
    "\n",
    "# ======================\n",
    "# 2) Parse timestamp\n",
    "# ======================\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"created_at\"])\n",
    "\n",
    "# ======================\n",
    "# 3) Sort chronologically\n",
    "# ======================\n",
    "df = df.sort_values(\"created_at\").reset_index(drop=True)\n",
    "\n",
    "# ======================\n",
    "# 4) Clean text for filtering\n",
    "# ======================\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'http\\S+', ' ', text)       # URLs\n",
    "    text = re.sub(r'@\\w+', ' ', text)         # mentions\n",
    "    text = re.sub(r'#\\w+', ' ', text)         # hashtags\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # whitespace\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# ======================\n",
    "# 5) Filter > 2 words\n",
    "# ======================\n",
    "df[\"word_count\"] = df[\"clean_text\"].str.split().apply(len)\n",
    "filtered = df[df[\"word_count\"] > 2].copy()\n",
    "\n",
    "print(\"Available for sampling:\", len(filtered))\n",
    "\n",
    "# ======================\n",
    "# 6) Separate abusive/non-abusive pools\n",
    "# ======================\n",
    "abusive = filtered[filtered[\"is_abusive\"] == 1]\n",
    "non_abusive = filtered[filtered[\"is_abusive\"] == 0]\n",
    "\n",
    "print(\"Abusive available:\", len(abusive))\n",
    "print(\"Non-abusive available:\", len(non_abusive))\n",
    "\n",
    "# ======================\n",
    "# 7) Sample 250 of each (or fallback to max available)\n",
    "# ======================\n",
    "np.random.seed(42)\n",
    "\n",
    "num_each = 250\n",
    "\n",
    "sample_abusive = abusive.sample(\n",
    "    n=min(num_each, len(abusive)),\n",
    "    replace=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sample_non_abusive = non_abusive.sample(\n",
    "    n=min(num_each, len(non_abusive)),\n",
    "    replace=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine\n",
    "sampled = pd.concat([sample_abusive, sample_non_abusive], ignore_index=True)\n",
    "\n",
    "# Shuffle to avoid ordering bias\n",
    "sampled = sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Final sample size:\", len(sampled))\n",
    "\n",
    "# ======================\n",
    "# 8) Save for human labeling\n",
    "# ======================\n",
    "keep_cols = ['tweet_id', 'original_text']\n",
    "out_path_without_lable = os.path.join(data_path, \"labled_by_human.csv\")\n",
    "sampled[keep_cols].to_csv(out_path_without_lable, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path_without_lable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311b704",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
