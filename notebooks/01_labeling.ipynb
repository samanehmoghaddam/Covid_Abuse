{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f14b609",
   "metadata": {},
   "source": [
    "## complete multi-round labeling notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f50ef",
   "metadata": {},
   "source": [
    "1. Initialization Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c0282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --------------------------------\n",
    "# SETUP\n",
    "# --------------------------------\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"..\", \"data\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Source file\n",
    "SOURCE_FILE = os.path.join(DATA_DIR, \"remaining_to_label_14.csv\")\n",
    "\n",
    "# Growing master\n",
    "MASTER_FILE = os.path.join(DATA_DIR, \"full_covid_abuse.csv\")\n",
    "\n",
    "# Remaining unlabeled <- output\n",
    "REMAINING_FILE = os.path.join(DATA_DIR, \"remaining_to_label_15.csv\")\n",
    "\n",
    "# Batch files\n",
    "BATCH_DIR = os.path.join(DATA_DIR, \"batches_14\")\n",
    "CHUNK_DIR = os.path.join(BATCH_DIR, \"chunks\")\n",
    "OUTPUT_DIR = os.path.join(BATCH_DIR, \"outputs\")\n",
    "\n",
    "for d in [BATCH_DIR, CHUNK_DIR, OUTPUT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# LOAD API KEY\n",
    "# --------------------------------\n",
    "env_path = os.path.join(BASE_DIR, \"..\", \"credentials\", \"openai.env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "TEXT_COL = \"original_text\"\n",
    "TEMP = 0\n",
    "\n",
    "print(\"Initialization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb077a",
   "metadata": {},
   "source": [
    "2. Load Data or Resume State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf881b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded master: 1884097 rows\n",
      "Remaining to label: 140000\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# If MASTER_FILE exists, resume\n",
    "# --------------------------------------\n",
    "if os.path.exists(MASTER_FILE):\n",
    "    master_df = pd.read_csv(MASTER_FILE, dtype=str)\n",
    "    print(f\"Loaded master: {len(master_df)} rows\")\n",
    "\n",
    "else:\n",
    "    # First round: start fresh\n",
    "    src = pd.read_csv(SOURCE_FILE, dtype=str)\n",
    "    src[\"is_abusive\"] = None\n",
    "    src[\"new_covid_terms\"] = None\n",
    "    src[\"label_round\"] = None\n",
    "\n",
    "    master_df = src.copy()\n",
    "    print(f\"Initialized master: {len(master_df)} rows\")\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Compute remaining\n",
    "# --------------------------------------\n",
    "remaining_df = master_df[master_df[\"is_abusive\"].isnull()].copy()\n",
    "\n",
    "# =======================================================\n",
    "#  Shuffle the unlabeled rows\n",
    "# =======================================================\n",
    "remaining_df = remaining_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Remaining to label:\", len(remaining_df))\n",
    "\n",
    "remaining_df.to_csv(REMAINING_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b19913e",
   "metadata": {},
   "source": [
    "3. Define Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ca5d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert in abusive language detection and content moderation.\n",
    "\n",
    "Given ONE tweet, perform:\n",
    "\n",
    "1. Abusive vs Non-abusive:\n",
    "   - Return \"abusive\": 1 if the tweet contains insulting, demeaning, harassing,\n",
    "     hateful, threatening, or abusive language (explicit or implicit).\n",
    "   - Otherwise return \"abusive\": 0.\n",
    "\n",
    "2. Detect newly coined pandemic or COVID-related terms, hashtags, or neologisms,\n",
    "   such as \"scamdemic\", \"plandemic\", \"covidiot\", \"anti-masker\", \"no-mask\",\n",
    "   \"anti-vax\", \"anti-vaxxer\", and similar COVID-era conspiracy or slang terms.\n",
    "   Return them as a JSON list of strings (empty list if none).\n",
    "\n",
    "Return ONLY a single JSON object in the format:\n",
    "{\n",
    "  \"abusive\": 0 or 1,\n",
    "  \"new\": [\"term1\", \"term2\"]\n",
    "}\n",
    "\n",
    "Do NOT return arrays. Do NOT return explanations. Do NOT add extra fields.\n",
    "Use double quotes only.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90fafad",
   "metadata": {},
   "source": [
    "4. Generate JSONL Batch Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d26f8a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL ready: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\batch_master.jsonl\n"
     ]
    }
   ],
   "source": [
    "JSONL_MASTER = os.path.join(BATCH_DIR, \"batch_master.jsonl\")\n",
    "\n",
    "with open(JSONL_MASTER, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in remaining_df.iterrows():\n",
    "\n",
    "        req = {\n",
    "            \"custom_id\": str(row[\"tweet_id\"]),\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": str(row[TEXT_COL]).replace(\"\\n\", \" \")}\n",
    "                ],\n",
    "                \"temperature\": TEMP\n",
    "            }\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "print(\"JSONL ready:\", JSONL_MASTER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7686e86",
   "metadata": {},
   "source": [
    "5. Chunk the JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25d467ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 7\n"
     ]
    }
   ],
   "source": [
    "MAX_LINES = 20000\n",
    "\n",
    "chunk_files = []\n",
    "chunk_id = 0\n",
    "line_count = 0\n",
    "\n",
    "out = None\n",
    "\n",
    "with open(JSONL_MASTER, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line_count % MAX_LINES == 0:\n",
    "            if out:\n",
    "                out.close()\n",
    "            fp = os.path.join(CHUNK_DIR, f\"chunk_{chunk_id}.jsonl\")\n",
    "            out = open(fp, \"w\", encoding=\"utf-8\")\n",
    "            chunk_files.append(fp)\n",
    "            chunk_id += 1\n",
    "\n",
    "        out.write(line)\n",
    "        line_count += 1\n",
    "\n",
    "if out:\n",
    "    out.close()\n",
    "\n",
    "print(\"Chunks:\", len(chunk_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf196d92",
   "metadata": {},
   "source": [
    "6. Upload + Create Batch Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f9c045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: batch_6937a4176458819092abb1e1c80fd813\n",
      "Started: batch_6937a42dd21081909d18771244f3d8fe\n",
      "Started: batch_6937a43cc55481908f6873b09abc0c11\n",
      "Started: batch_6937a44f7b9c8190be60bf4c50237d3d\n",
      "Started: batch_6937a45ebe608190920dc83fcbab0384\n",
      "Started: batch_6937a46cec8c81908f5dd9af4cf08126\n",
      "Started: batch_6937a47c32f081909115e22187c11849\n"
     ]
    }
   ],
   "source": [
    "batch_ids = []\n",
    "\n",
    "def upload_and_create(path):\n",
    "    upload = client.files.create(file=open(path, \"rb\"), purpose=\"batch\")\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=upload.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "    return batch.id\n",
    "\n",
    "for fp in chunk_files:\n",
    "    b_id = upload_and_create(fp)\n",
    "    batch_ids.append(b_id)\n",
    "    print(\"Started:\", b_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d160881",
   "metadata": {},
   "source": [
    "7. Poll Until Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bcb3dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polling for completion ...\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → validating\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → validating\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → in_progress\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → in_progress\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → in_progress\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 7 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → in_progress\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a46cec8c81908f5dd9af4cf08126 → completed\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 6 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 6 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → in_progress\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → in_progress\n",
      "Checking: 6 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → finalizing\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 6 batches\n",
      "batch_6937a4176458819092abb1e1c80fd813 → completed\n",
      "batch_6937a42dd21081909d18771244f3d8fe → in_progress\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 5 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 5 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a45ebe608190920dc83fcbab0384 → completed\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → finalizing\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 4 batches\n",
      "batch_6937a42dd21081909d18771244f3d8fe → completed\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 3 batches\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → finalizing\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 3 batches\n",
      "batch_6937a43cc55481908f6873b09abc0c11 → completed\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 2 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → finalizing\n",
      "Checking: 2 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "batch_6937a47c32f081909115e22187c11849 → completed\n",
      "Checking: 1 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "Checking: 1 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "Checking: 1 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "Checking: 1 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → finalizing\n",
      "Checking: 1 batches\n",
      "batch_6937a44f7b9c8190be60bf4c50237d3d → completed\n",
      "All batches finished.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Polling for completion ...\")\n",
    "\n",
    "pending = batch_ids.copy()\n",
    "\n",
    "while pending:\n",
    "    print(\"Checking:\", len(pending), \"batches\")\n",
    "    finished = []\n",
    "    for b in pending:\n",
    "        s = client.batches.retrieve(b)\n",
    "        print(b, \"→\", s.status)\n",
    "        if s.status in [\"completed\", \"failed\"]:\n",
    "            finished.append(b)\n",
    "\n",
    "    pending = [b for b in pending if b not in finished]\n",
    "    time.sleep(120)\n",
    "\n",
    "print(\"All batches finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5608b",
   "metadata": {},
   "source": [
    "8. Download Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf20151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a4176458819092abb1e1c80fd813.jsonl\n",
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a42dd21081909d18771244f3d8fe.jsonl\n",
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a43cc55481908f6873b09abc0c11.jsonl\n",
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a44f7b9c8190be60bf4c50237d3d.jsonl\n",
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a45ebe608190920dc83fcbab0384.jsonl\n",
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a46cec8c81908f5dd9af4cf08126.jsonl\n",
      "Downloaded: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\batches_14\\outputs\\batch_6937a47c32f081909115e22187c11849.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_files = []\n",
    "\n",
    "for b in batch_ids:\n",
    "    status = client.batches.retrieve(b)\n",
    "    out_id = status.output_file_id\n",
    "\n",
    "    if not out_id:\n",
    "        print(\"No output for:\", b)\n",
    "        continue\n",
    "\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"{b}.jsonl\")\n",
    "\n",
    "    body = client.files.content(out_id).read()\n",
    "\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(body)\n",
    "\n",
    "    output_files.append(out_path)\n",
    "    print(\"Downloaded:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ed069",
   "metadata": {},
   "source": [
    "9. Parse and Merge Results Into Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc90fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Parsed rows: 140000\n",
      "Bad JSON rows: 0\n",
      "======================================\n",
      "results_df rows: 140000\n",
      "Current max round: 13.0\n",
      "This batch is round: 14\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "bad = []\n",
    "\n",
    "# ------------------------------------\n",
    "# Parse each output file safely\n",
    "# ------------------------------------\n",
    "for fp in output_files:\n",
    "    with open(fp, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                resp = json.loads(line)\n",
    "            except Exception as e:\n",
    "                print(\"FAILED to load JSON line, skipping:\", line[:200])\n",
    "                continue\n",
    "\n",
    "            tid = resp.get(\"custom_id\")\n",
    "\n",
    "            try:\n",
    "                content = resp[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            except Exception:\n",
    "                bad.append((tid, \"MISSING content\"))\n",
    "                results[tid] = {\"abusive\": None, \"new\": []}\n",
    "                continue\n",
    "\n",
    "            # Try to parse JSON returned by the model\n",
    "            try:\n",
    "                parsed = json.loads(content)\n",
    "            except Exception:\n",
    "                bad.append((tid, content))\n",
    "                parsed = {\"abusive\": None, \"new\": []}\n",
    "\n",
    "            results[tid] = parsed\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"Parsed rows:\", len(results))\n",
    "print(\"Bad JSON rows:\", len(bad))\n",
    "print(\"======================================\")\n",
    "\n",
    "# ======================================================\n",
    "# Save bad responses for inspection\n",
    "# ======================================================\n",
    "if bad:\n",
    "    bad_df = pd.DataFrame(bad, columns=[\"tweet_id\", \"raw_content\"])\n",
    "    bad_path = os.path.join(DATA_DIR, \"bad_json_responses_round.csv\")\n",
    "    bad_df.to_csv(bad_path, index=False)\n",
    "    print(\"Saved bad responses to:\", bad_path)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# BUILD results_df\n",
    "# ======================================================\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"tweet_id\": tid,\n",
    "        \"is_abusive\": v.get(\"abusive\", None),\n",
    "        \"new_covid_terms\": json.dumps(v.get(\"new\", []))\n",
    "    }\n",
    "    for tid, v in results.items()\n",
    "])\n",
    "\n",
    "print(\"results_df rows:\", len(results_df))\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Ensure numeric label_round\n",
    "# ======================================================\n",
    "if \"label_round\" not in master_df.columns:\n",
    "    master_df[\"label_round\"] = None\n",
    "\n",
    "master_df[\"label_round\"] = pd.to_numeric(master_df[\"label_round\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Determine next round number\n",
    "# ======================================================\n",
    "current_max = master_df[\"label_round\"].max()\n",
    "if pd.isna(current_max):\n",
    "    current_max = 0\n",
    "\n",
    "next_round = int(current_max) + 1\n",
    "\n",
    "print(\"Current max round:\", current_max)\n",
    "print(\"This batch is round:\", next_round)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Assign round to this batch\n",
    "# ======================================================\n",
    "results_df[\"label_round\"] = next_round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f1dcf",
   "metadata": {},
   "source": [
    "10. Merge Without Overwritting Past Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd07faf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master saved: c:\\Users\\Sama\\Documents\\Active learninig\\experiments\\notebooks\\..\\data\\covid_tweets\\classified_master.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "master_df = master_df.merge(\n",
    "    results_df,\n",
    "    on=\"tweet_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_new\")\n",
    ")\n",
    "\n",
    "# Only fill missing\n",
    "master_df[\"is_abusive\"] = master_df[\"is_abusive\"].fillna(master_df[\"is_abusive_new\"])\n",
    "master_df[\"new_covid_terms\"] = master_df[\"new_covid_terms\"].fillna(master_df[\"new_covid_terms_new\"])\n",
    "\n",
    "# If label_round is empty and we just filled it → set round\n",
    "master_df[\"label_round\"] = master_df[\"label_round\"].fillna(master_df[\"label_round_new\"])\n",
    "\n",
    "# Drop temp\n",
    "master_df = master_df.drop(columns=[\"is_abusive_new\", \"new_covid_terms_new\", \"label_round_new\"], errors=\"ignore\")\n",
    "\n",
    "master_df.to_csv(MASTER_FILE, index=False)\n",
    "print(\"Master saved:\", MASTER_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457816e3",
   "metadata": {},
   "source": [
    "11. Generate Next Iteration Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ab97d081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining for next round: 0\n"
     ]
    }
   ],
   "source": [
    "remaining_df = master_df[master_df[\"is_abusive\"].isnull()].copy()\n",
    "remaining_df = remaining_df.sample(frac=1, random_state=42)\n",
    "\n",
    "remaining_df.to_csv(REMAINING_FILE, index=False)\n",
    "\n",
    "print(\"Remaining for next round:\", len(remaining_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bca0e",
   "metadata": {},
   "source": [
    "13. Summary Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c77bad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ SUMMARY ================\n",
      "\n",
      "Master total rows: 1884097\n",
      "Labeled rows: 1884097\n",
      "Remaining rows: 0\n",
      "Latest round: 14.0\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ SUMMARY ================\\n\")\n",
    "print(\"Master total rows:\", len(master_df))\n",
    "print(\"Labeled rows:\", master_df[\"is_abusive\"].notnull().sum())\n",
    "print(\"Remaining rows:\", len(remaining_df))\n",
    "print(\"Latest round:\", master_df[\"label_round\"].max())\n",
    "print(\"\\n========================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331e211",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
